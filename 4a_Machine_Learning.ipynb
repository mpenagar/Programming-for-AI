{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7b66dc-ed3a-4f3a-83d4-d2c39648a5e5",
   "metadata": {},
   "source": [
    "Types of MAchine Learning Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168170a3-91ed-4e2d-89cd-b4f387552d03",
   "metadata": {},
   "source": [
    "## Learning Paradigms and Machine Learning Tasks\n",
    "\n",
    "Machine learning tasks can be categorized according to the learning paradigm and the specific goal they pursue:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b50337-9f3f-4388-a6ac-2e319bed2a42",
   "metadata": {},
   "source": [
    "* Supervised Learning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7460d0-bc42-4f59-9beb-478e5b9aec74",
   "metadata": {},
   "source": [
    "* Unsupervised Learning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a813a-0ae3-4c1d-9655-0b5eda762040",
   "metadata": {},
   "source": [
    "* Semi-Supervised Learning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0a291-ebfd-43b9-a3df-0d33e10846fe",
   "metadata": {},
   "source": [
    "* Self-Supervised Learning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986429b-cefd-4228-923b-00b797c8f630",
   "metadata": {},
   "source": [
    "* Reinforcement Learning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1d266-fd45-4cf4-9e7e-f17dd69c92d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0497289-f09e-4d3e-952d-8f5ad92cf633",
   "metadata": {},
   "source": [
    "There are several different types of tasks in machine learning, broadly categorized by the learning paradigm and the specific goal. Here's a breakdown of the main categories and some common tasks within them:   \n",
    "\n",
    "* Supervised Learning: In supervised learning, the algorithm learns from labeled data, meaning each data point is associated with a known output or target variable. The goal is to learn a mapping function that can predict the output for new, unseen input data.   \n",
    "\n",
    "   * Classification: The goal is to assign data points to predefined categories or classes. The output variable is discrete.\n",
    "      * Binary Classification: Predicting one of two classes (e.g., spam/not spam, cat/dog).   \n",
    "      * Multi-class Classification: Predicting one of more than two classes (e.g., identifying different types of flowers, classifying news articles into topics).   \n",
    "  \n",
    "   * Regression: The goal is to predict a continuous numerical value. The output variable is continuous.\n",
    "      *Linear Regression: Predicting a value based on a linear relationship with the input features (e.g., predicting house prices based on size).   \n",
    "      * Polynomial Regression: Predicting a value based on a polynomial relationship with the input features.   \n",
    "      * Time Series Forecasting: Predicting future values in a sequence based on past values (e.g., predicting stock prices, weather forecasting).   \n",
    "  \n",
    "* Unsupervised Learning: In unsupervised learning, the algorithm learns from unlabeled data, without any explicit output or target variable. The goal is to discover hidden patterns, structures, or relationships in the data.   \n",
    "\n",
    "   * Clustering: Grouping similar data points together based on their features without prior knowledge of the groups (e.g., customer segmentation, document analysis).\n",
    "      * K-Means Clustering: Partitioning data into k clusters based on distance to centroids.   \n",
    "      * Hierarchical Clustering: Creating a tree-like structure of clusters.   \n",
    "      * Density-Based Clustering: Identifying clusters based on the density of data points.   \n",
    "  \n",
    "   * Dimensionality Reduction: Reducing the number of features in a dataset while preserving its essential information (e.g., data visualization, feature extraction).\n",
    "      * Principal Component Analysis (PCA): Finding the principal components that capture the most variance in the data.   \n",
    "      * t-distributed Stochastic Neighbor Embedding (t-SNE): Reducing dimensionality for visualizing high-dimensional data.   \n",
    "  \n",
    "   * Association Rule Mining: Discovering interesting relationships or associations between variables in large datasets (e.g., market basket analysis).\n",
    "      * Apriori Algorithm: Finding frequent itemsets in transactional data.   \n",
    "      * Eclat Algorithm: Another algorithm for finding frequent itemsets.   \n",
    "  \n",
    "   * Anomaly Detection: Identifying data points that deviate significantly from the normal behavior or patterns in the data (e.g., fraud detection, fault detection).   \n",
    "\n",
    "* Reinforcement Learning: In reinforcement learning, an agent learns to interact with an environment by taking actions and receiving rewards or penalties. The goal is for the agent to learn an optimal policy (a mapping from states to actions) that maximizes the cumulative reward over time.   \n",
    "\n",
    "   * Control Tasks: Learning to control a system or agent to achieve a specific goal (e.g., robotics, autonomous driving).\n",
    "   * Game Playing: Training agents to play games against opponents (e.g., AlphaGo, Atari games).   \n",
    "   * Recommendation Systems: Optimizing recommendations based on user feedback and rewards.   \n",
    "   * Resource Management: Learning to allocate resources efficiently.   \n",
    "\n",
    "* Other Types of Machine Learning Tasks (Sometimes Considered Subcategories or Hybrid Approaches):\n",
    "\n",
    "   * Semi-Supervised Learning: Learning from a combination of labeled and unlabeled data. This is useful when labeling data is expensive or time-consuming.   \n",
    "   * Self-Supervised Learning: Learning from unlabeled data where the labels are generated from the data itself through a pretext task (e.g., predicting a missing part of an image). The learned representations can then be used for downstream supervised tasks.   \n",
    "   * Machine Translation: Translating text from one language to another. This can be approached with sequence-to-sequence models in supervised learning.   \n",
    "   * Transcription: Converting unstructured data like audio into a structured format like text (e.g., speech recognition).   \n",
    "Synthesis and Sampling: Generating new data samples that are similar to the training data (e.g., generating images, text, or music).\n",
    "\n",
    "The choice of machine learning task depends heavily on the nature of the data, the problem you are trying to solve, and the desired outcome. Understanding these different types of tasks is fundamental to applying machine learning effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd9f08-711a-4873-b84f-54f7a1e6eea2",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "\n",
    "* Multi-class Classification Task &rarr; Iris Dataset\n",
    "   * Number of Instances: 150\n",
    "   * Number of Features: 4 (sepal length, sepal width, petal length, petal width)\n",
    "   * Number of classes: 4\n",
    "* Binary Classification Task &rarr; Breast Cancer Wisconsin (Diagnostic) Dataset\n",
    "   * Number of Instances: 569\n",
    "   * Number of Features: 30 (real-valued features computed from digitized images of cell nuclei)\n",
    "   * Number of classes: 2 (Malignant/Benign)\n",
    "* Regression Task &rarr; Wine Quality Dataset\n",
    "   * Number of Instances: 4,900\n",
    "   * Number of Features: 11 (physicochemical tests)\n",
    "   * Prediction: quality score\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a71433-fc82-4ad1-a065-128b6094d2e9",
   "metadata": {},
   "source": [
    "## Data Spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421c11b-42e2-4f78-a52b-237b4a550002",
   "metadata": {},
   "source": [
    "Divide a dataset into two or more subsets to train, validate, and evaluate a *Machine Learning* model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c8036-ab52-450a-b4b1-6df6452f99e6",
   "metadata": {},
   "source": [
    "* **Training Set**: The largest portion of the data (tipically 70-80%), used to train the model (learn **patterns and relationships** in the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d9af8-e4a4-4bf7-b93b-595d91e961a6",
   "metadata": {},
   "source": [
    "* **Validation/Development  Set**: A smaller portion of the data (tipically 10-15%), used to tune the model's hyperparameters and assess its performance during training. It helps prevent **overfitting** by providing an **unbiased** evaluation while adjusting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4408055-d602-4910-9731-5a3e24b35ea1",
   "metadata": {},
   "source": [
    "* **Test  Set**: Another smaller portion of the data (tipically 10-15%), used for the final evaluation of the trained model's performance. It provides an unbiased estimate of how well the model will perform on completely new, unseen data. The model **does not learn from this set** during training or hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17843be1-20b3-481e-bf56-b3928890ad9e",
   "metadata": {},
   "source": [
    "### Importance of Data Spliting \n",
    "\n",
    "* **Prevent Overfitting**: By evaluating the model on data unseen during training (validation/test sets), we can check if the model has **learned generalizable patterns** (instead of **memorizing** the training data itself).\n",
    "  \n",
    "* **Model Selection and Hyperparameter Tuning**: The validation set allows us to compare different models and their configurations (hyperparameters) to choose the one that performs best on unseen data.\n",
    "\n",
    "* **Assess Generalization**: The test set provides a final, unbiased estimate of the model's **ability to generalize to new data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e9d8d-0149-4c89-9230-5ac802550838",
   "metadata": {},
   "source": [
    "### Data Splitting Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233d355-5bc6-4a38-be8a-c31903c89e8b",
   "metadata": {},
   "source": [
    "* **Train-Test Split**: The simplest (and possibly wrong) method. Does not allow hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafdf1bb-de9b-4220-91f8-c874ecdd6e00",
   "metadata": {},
   "source": [
    "* **Train-Validation-Test Split**: The most common method. Divides the data into three sets for training, hyperparameter tuning, and final evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd68620-b128-4d03-8762-5fa19394f9cb",
   "metadata": {},
   "source": [
    "* **K-Fold Cross-Validation**: The dataset is divided into $k$ equal-sized *folds*. The model is trained and evaluated $k$ times, with each fold serving as the test set once and the remaining k−1 folds used for training. The performance is then averaged across all k evaluations. This provides a more robust estimate of performance, especially with smaller datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb5b64-55da-4db5-8af4-a7031ddbfad3",
   "metadata": {},
   "source": [
    "* **Time Series Split**: Used for time-dependent data, where the data is split chronologically. The training set consists of earlier time periods, and the test set consists of later time periods, preventing *looking into the future* during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8635da-cec0-49a5-ad0b-30f5bf99541a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
